{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c1a848e-47b0-4b92-bf25-268a22c58a2c",
      "metadata": {
        "id": "0c1a848e-47b0-4b92-bf25-268a22c58a2c"
      },
      "source": [
        "# FIFA Virtual Try-On Training Colab âš½\n",
        "\n",
        "This Colab demo walks you through how to train a virtual try-on system. Note that the training strategies are toned down on purpose to demonstrate that it works end-to-end. Specifically, the dataset consists of only 100 image pairs and other labels. Further, for both stages the number of epochs are reduced. \n",
        "\n",
        "A full build training requires around a week or more on a single NVIDIA 3080Ti GPU. Full training details are available in [dktunited/fifa_train](https://github.com/dktunited/fifa_train)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6adec12-5164-49ad-b3da-9e54c154eb7c",
      "metadata": {
        "id": "f6adec12-5164-49ad-b3da-9e54c154eb7c"
      },
      "source": [
        "### Setup dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "LWvvSsPNLfTr"
      },
      "id": "LWvvSsPNLfTr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb\n",
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "cpxpHz0_K3Z2"
      },
      "id": "cpxpHz0_K3Z2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone repository."
      ],
      "metadata": {
        "id": "3t9bkzeF99MU"
      },
      "id": "3t9bkzeF99MU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52be2f2-8f13-42a5-9664-905d61da8fac",
      "metadata": {
        "id": "c52be2f2-8f13-42a5-9664-905d61da8fac"
      },
      "outputs": [],
      "source": [
        "# Clone private repo in this format\n",
        "# !git clone https://username:access-token@github.com/dktunited/repo-name.git\n",
        "# %cd repo_id\n",
        "\n",
        "# An example\n",
        "# !git clone https://hasibzunair:my_token@github.com/dktunited/fifa_train.git\n",
        "%cd fifa_train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR, upload the private repo zip file. Uncomment if you want to use it."
      ],
      "metadata": {
        "id": "KsBevIYrNGYv"
      },
      "id": "KsBevIYrNGYv"
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# !unzip ./decathlon-virtual-tryon-main.zip -d ./\n",
        "# %cd decathlon-virtual-tryon-main/"
      ],
      "metadata": {
        "id": "hLA6-n0uJyYk"
      },
      "id": "hLA6-n0uJyYk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473fcbb4-6b99-4a66-a4ba-49a3bfe603aa",
      "metadata": {
        "id": "473fcbb4-6b99-4a66-a4ba-49a3bfe603aa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e501b7-6c57-4039-b8c6-07ae04453cbf",
      "metadata": {
        "id": "e4e501b7-6c57-4039-b8c6-07ae04453cbf"
      },
      "outputs": [],
      "source": [
        "# Get model for computing VGG based distance loss while training\n",
        "os.system(\"wget -O ./train_src/models/vgg19-dcbb9e9d.pth https://github.com/hasibzunair/residual-acgpn/releases/download/v0.1/vgg19-dcbb9e9d.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd93878-56b3-44e8-a81c-68cb2b759369",
      "metadata": {
        "id": "7dd93878-56b3-44e8-a81c-68cb2b759369"
      },
      "source": [
        "### Get dataset\n",
        "\n",
        "See [dataset releases](https://github.com/dktunited/fifa_train/releases/tag/v1.0-data) for more options. Note that using them requires around a week of training on a single GPU. If you use any of those datasets, you need to modify the code snippet below to retrieve the desired dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81e0b5b-65bd-4139-9960-503f0b9f99eb",
      "metadata": {
        "id": "a81e0b5b-65bd-4139-9960-503f0b9f99eb"
      },
      "outputs": [],
      "source": [
        "os.system(\"mkdir ./datasets\")\n",
        "if not os.path.exists(\"./decavton_subset_data/\"):\n",
        "    os.system(\"wget -O ./datasets/decavton_subset_data.zip https://github.com/hasibzunair/my-lfs/releases/download/v1-datasets/decavton_subset_data.zip\")\n",
        "    os.system(\"unzip ./datasets/decavton_subset_data.zip -d ./datasets/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66134fe8-39c1-4ce0-8eb4-6a2c8301a34a",
      "metadata": {
        "id": "66134fe8-39c1-4ce0-8eb4-6a2c8301a34a"
      },
      "source": [
        "### Train Fabricator\n",
        "\n",
        "**NOTE (VERY IMPORTANT)**: Before training, go to `train_src/data/aligned_dataset.py` and change value from 120000 to 50 in L153 and L154. This is because the random masks required for inpainting during training are selected randomly from a collection of 12000 image masks. Large number of files in Colab results in missing files or corrupted files. So a subset of the image masks are used for this demo training."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For better performance, ideally `niter` and `niter_decay` are both set to 100, instead of 10 in this case. Both `niter` and `niter_decay` should be equal."
      ],
      "metadata": {
        "id": "8kntU6d-bcrA"
      },
      "id": "8kntU6d-bcrA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb277172-4370-4213-8c9d-5c292396befc",
      "metadata": {
        "id": "eb277172-4370-4213-8c9d-5c292396befc"
      },
      "outputs": [],
      "source": [
        "%cd train_src\n",
        "!python train_fabricator.py --name \"deca_viton_fabricator\" --dataroot \"../datasets/decavton_subset_data/decavton_subset_train\" --niter 10 --niter_decay 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114009f7-f98a-49af-9c6b-6e1c3db17a8f",
      "metadata": {
        "id": "114009f7-f98a-49af-9c6b-6e1c3db17a8f"
      },
      "source": [
        "To inspect the outputs of fabricator, go to `train_src/sample`. You will find three folders, which are the masked inputs, original inputs and the predicted outputs. Ideally, the predicted outputs should match the original inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55479b48-3e7b-4069-9630-64f8f992cdc3",
      "metadata": {
        "id": "55479b48-3e7b-4069-9630-64f8f992cdc3"
      },
      "source": [
        "### Train Virtual Try-On pipeline\n",
        "This step takes over a week to run on a single GPU when using the actual datasets (e.g. VITON, Decathlon VTON). \n",
        "\n",
        "For better performance, ideally `niter` and `niter_decay` are both set to 100, instead of 10 in this case. Both `niter` and `niter_decay` should be equal.\n",
        "\n",
        "**Note**: Colab timed out? Try this [hack](https://github.com/hasibzunair/colab-ml-project-template/blob/main/template.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1351908-8290-4be1-907e-8bb7e2b64a9a",
      "metadata": {
        "id": "d1351908-8290-4be1-907e-8bb7e2b64a9a"
      },
      "outputs": [],
      "source": [
        "!python train.py --name \"decavton_fifa\" --dataroot \"../datasets/decavton_subset_data/decavton_subset_train\" --niter 10 --niter_decay 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c14899f-1990-44ea-8a3a-7155c88a5cd0",
      "metadata": {
        "id": "6c14899f-1990-44ea-8a3a-7155c88a5cd0"
      },
      "source": [
        "Now you can find the model weights at `train_src/checkpoints`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef363fc-2058-4d9f-aefd-e5115ec22c0a",
      "metadata": {
        "id": "bef363fc-2058-4d9f-aefd-e5115ec22c0a"
      },
      "source": [
        "### Evaluated the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853bb22e-0772-45b4-8448-7f169697fc8c",
      "metadata": {
        "id": "853bb22e-0772-45b4-8448-7f169697fc8c"
      },
      "source": [
        "Computes SSIM and visualize on same person and cloth image pairs. See `test_src/outputs/all_same` for results. Here, the SSIM score would be roughly 0.7873."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74772930-7fb7-421e-b2ab-27a267e2ace5",
      "metadata": {
        "id": "74772930-7fb7-421e-b2ab-27a267e2ace5"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "%cd test_src\n",
        "!python test_decavton_same.py --exp_name \"decavton_fifa\" --test_dir \"../datasets/decavton_subset_data/decavton_subset_test\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1580491-9c2e-410a-b6ed-128b24b270b6",
      "metadata": {
        "id": "e1580491-9c2e-410a-b6ed-128b24b270b6"
      },
      "source": [
        "Now, get try-on results for random person and clothing image pairs. See `test_src/outputs/all` for results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d533c51-43b4-480c-a77a-add97cd4e54c",
      "metadata": {
        "id": "5d533c51-43b4-480c-a77a-add97cd4e54c"
      },
      "outputs": [],
      "source": [
        "!python test_decavton_random.py --exp_name \"decavton_fifa\" --test_dir \"../datasets/decavton_subset_data/decavton_subset_test\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc538d81-fc18-4737-90cd-dc9d37d91e6f",
      "metadata": {
        "id": "cc538d81-fc18-4737-90cd-dc9d37d91e6f"
      },
      "source": [
        "### Visualize results\n",
        "\n",
        "Let's visualize the same image pairs and compare to grounth truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1572fc48-805f-4a15-9a64-24aef33a5946",
      "metadata": {
        "id": "1572fc48-805f-4a15-9a64-24aef33a5946"
      },
      "outputs": [],
      "source": [
        "def visualize(path, idx, idx_flag=True, **images):\n",
        "    \"\"\"Plot images in one row.\"\"\"\n",
        "    if not os.path.exists(\"./outputs/vis\"):\n",
        "        os.mkdir(\"./outputs/vis\")\n",
        "    if not os.path.exists(os.path.join(\"./outputs/vis/\", path)):\n",
        "        os.mkdir(os.path.join(\"./outputs/vis/\", path))\n",
        "    \n",
        "    n = len(images)\n",
        "    fig = plt.figure(figsize=(60, 40))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        #if idx==0:\n",
        "        plt.title(' '.join(name.split('_')).lower(), fontsize=60)\n",
        "        if idx_flag:\n",
        "            if i ==0:\n",
        "                w,h = (1,25)\n",
        "                fs = 1.0\n",
        "                color = (0,0,0)\n",
        "                font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
        "                cv2.putText(image, str(idx), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "    plt.savefig(os.path.join(\"./outputs/vis/\", path, str(idx)), facecolor=\"white\", bbox_inches = 'tight')\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def make_dataset(dir):\n",
        "    images = []\n",
        "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
        "\n",
        "    f = dir.split('/')[-1].split('_')[-1]\n",
        "    #print (dir, f)\n",
        "    dirs= os.listdir(dir)\n",
        "    for img in dirs:\n",
        "\n",
        "        path = os.path.join(dir, img)\n",
        "        #print(path)\n",
        "        images.append(path)\n",
        "    return images\n",
        "\n",
        "def read_image(path):\n",
        "    image = cv2.imread(path, -1)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "# Get same tryon outputs\n",
        "config_name = \"decavton_fifa\"\n",
        "outputs_same = \"./outputs/{}/{}/\".format(config_name, \"all_same\")\n",
        "tryons_same_paths = sorted(make_dataset(outputs_same))\n",
        "\n",
        "# Get same person and clothing images\n",
        "test_dir_path = \"../datasets/decavton_subset_data/decavton_subset_test/\"\n",
        "persons = []\n",
        "clothes = []\n",
        "with open(os.path.join(\"../datasets/decavton_subset_data/decavton_subset_test/test_pairs.txt\"), 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        h_name, c_name = line.strip().split()\n",
        "        persons.append(h_name)\n",
        "        clothes.append(c_name)\n",
        "ref_person_paths = [os.path.join(test_dir_path, \"test_img\", x) for x in persons]\n",
        "target_clothes_paths = [os.path.join(test_dir_path, \"test_color\", x) for x in clothes]\n",
        "\n",
        "assert len(ref_person_paths) == len(target_clothes_paths), f\"Should be same, got {len(ref_person_paths)}, {len(target_clothes_paths)}\"\n",
        "assert len(ref_person_paths) == len(tryons_same_paths), f\"Should be same, got {len(ref_person_paths)}, {len(tryons_same_paths)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7077a3c8-66e4-4a40-b5a9-dce57c14830e",
      "metadata": {
        "id": "7077a3c8-66e4-4a40-b5a9-dce57c14830e"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for num in range(10):\n",
        "    visualize(\"tryons_same\", i, reference_person=read_image(ref_person_paths[num]), target_clothes=read_image(target_clothes_paths[num]),\n",
        "              tryon=read_image(tryons_same_paths[num]))\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9522b298-76c0-49d6-b0cc-4e0defbcfa94",
      "metadata": {
        "id": "9522b298-76c0-49d6-b0cc-4e0defbcfa94"
      },
      "source": [
        "Let's visualize some random image pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27315b51-e4d6-4edf-be5e-a66f3d13b8cf",
      "metadata": {
        "id": "27315b51-e4d6-4edf-be5e-a66f3d13b8cf"
      },
      "outputs": [],
      "source": [
        "# Get random tryon outputs\n",
        "config_name = \"decavton_fifa\"\n",
        "outputs_same = \"./outputs/{}/{}/\".format(config_name, \"all\")\n",
        "tryons_same_paths = sorted(make_dataset(outputs_same))\n",
        "\n",
        "# Get random person and clothing images\n",
        "test_dir_path = \"../datasets/decavton_subset_data/decavton_subset_test/\"\n",
        "persons = []\n",
        "clothes = []\n",
        "with open(os.path.join(\"../datasets/decavton_subset_data/decavton_subset_test/test_pairs_random.txt\"), 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        h_name, c_name = line.strip().split()\n",
        "        persons.append(h_name)\n",
        "        clothes.append(c_name)\n",
        "ref_person_paths = [os.path.join(test_dir_path, \"test_img\", x) for x in persons]\n",
        "target_clothes_paths = [os.path.join(test_dir_path, \"test_color\", x) for x in clothes]\n",
        "\n",
        "assert len(ref_person_paths) == len(target_clothes_paths), f\"Should be same, got {len(ref_person_paths)}, {len(target_clothes_paths)}\"\n",
        "assert len(ref_person_paths) == len(tryons_same_paths), f\"Should be same, got {len(ref_person_paths)}, {len(tryons_same_paths)}\"\n",
        "\n",
        "i = 0\n",
        "for num in range(10):\n",
        "    visualize(\"tryons_random\", i, reference_person=read_image(ref_person_paths[num]), target_clothes=read_image(target_clothes_paths[num]),\n",
        "              tryon=read_image(tryons_same_paths[num]))\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68e9b6de-0e10-4b4b-8780-fff2c25a37dd",
      "metadata": {
        "id": "68e9b6de-0e10-4b4b-8780-fff2c25a37dd"
      },
      "source": [
        "The results are not that good because this model has been training on only 100 image pairs for few number of epochs. This whole pipeline can be be trained on the larger datasets such as VITON, Deca VTON or DecaVTON + VITON by simply getting the larger datasets instead of the subset. The weights can also be used for inference in the Colab demo https://github.com/dktunited/fifa_demo. You would need to download the files like done below and then transfer it to your colab demo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model weights\n",
        "\n",
        "Now, we can download the virtual try-on model weights to use in a separate colab demo or an interactive app. The download will take some time to complete as the models files are close to 500MB.\n",
        "\n",
        "See more at [dkunited/fifa_demo](https://github.com/dktunited/fifa_demo)."
      ],
      "metadata": {
        "id": "OjtdDCBUt7zR"
      },
      "id": "OjtdDCBUt7zR"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "wXnFnjAlwUyi"
      },
      "id": "wXnFnjAlwUyi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move necessary files to a folder and zip\n",
        "!mkdir ./train_src/checkpoints/decavtonfifa\n",
        "!mv ./train_src/checkpoints/decavton_fifa/latest_net_U.pth ./train_src/checkpoints/decavton_fifa/latest_net_G1.pth ./train_src/checkpoints/decavton_fifa/latest_net_G2.pth ./train_src/checkpoints/decavton_fifa/latest_net_G.pth ./train_src/checkpoints/decavtonfifa/\n",
        "!zip -r ./train_src/checkpoints/decavtonfifa.zip ./train_src/checkpoints/decavtonfifa/\n",
        "# Download zip file\n",
        "from google.colab import files\n",
        "files.download(\"./train_src/checkpoints/decavtonfifa.zip\")"
      ],
      "metadata": {
        "id": "uZesmX4KvWoo"
      },
      "id": "uZesmX4KvWoo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sy4YEwO8kK9C"
      },
      "id": "Sy4YEwO8kK9C",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "train_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}