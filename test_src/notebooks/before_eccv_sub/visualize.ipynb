{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08843315-3609-4c67-b1f3-29922d30ed85",
   "metadata": {},
   "source": [
    "## Visualize outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2f59d4-2cfb-4a40-9562-3d54f5c87d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c27a4a-2cd5-4e55-ac51-848259cb2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "macos = True\n",
    "if macos == True:\n",
    "    rc('font',**{'family':'sans-serif','sans-serif':['Computer Modern Roman']})\n",
    "    rc('text', usetex=True)\n",
    "\n",
    "# Font Size\n",
    "import matplotlib\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 30}\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdce517-31de-477f-8708-ce4f6e61876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare-tryons-all -> visualize tryon images of different clothing for each configuration\n",
    "#\n",
    "\n",
    "def visualize(idx, **images):\n",
    "    \"\"\"Plot images in one row.\"\"\" \n",
    "    n = len(images)\n",
    "    fig = plt.figure(figsize=(60, 40))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        #if idx==0:\n",
    "        plt.title(' '.join(name.split('_')).lower(), fontsize=40)\n",
    "        if i ==0:\n",
    "            w,h = (1,25)\n",
    "            fs = 1.0\n",
    "            color = (0,0,0)\n",
    "            #color = (255,255,255)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "            cv2.putText(image, str(idx), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        #plt.tight_layout()\n",
    "    plt.savefig(\"../outputs/vis/compare-warprefs/{}.png\".format(idx), facecolor=\"white\", bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "\n",
    "    f = dir.split('/')[-1].split('_')[-1]\n",
    "    #print (dir, f)\n",
    "    dirs= os.listdir(dir)\n",
    "    for img in dirs:\n",
    "\n",
    "        path = os.path.join(dir, img)\n",
    "        #print(path)\n",
    "        images.append(path)\n",
    "    return images\n",
    "\n",
    "def read_image(path):\n",
    "    image = cv2.imread(path, -1)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def read_image_(path):\n",
    "    image = cv2.imread(path, -1)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (192, 256))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59226d7-9286-4b5e-952c-fa9d8b3ea656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec3f342-be68-4dcf-9d41-06a16b424b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../outputs/robustness_random/acgpn_gen/.DS_Store': No such file or directory\n",
      "rm: cannot remove '../outputs/robustness_random/fifa_gen/.DS_Store': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm ../outputs/robustness_random/acgpn_gen/.DS_Store\n",
    "!rm ../outputs/robustness_random/fifa_gen/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953451ff-eb1e-4cf2-91c4-4246c85f1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to model outputs\n",
    "algo1 = \"cpvtonpp\"\n",
    "algo2 = \"acgpn_paper\"\n",
    "algo3 = \"with_res\"\n",
    "algo4 = \"with_all_res\"\n",
    "algo5 = \"with_res_msssim\"\n",
    "algo6 = \"final\"\n",
    "\n",
    "## New\n",
    "algo7 = decavton_fifa_wo_fab\":\n",
    "\n",
    "# Path to output tryon images\n",
    "#mode = \"all\" # all, all_same, easy, medium, hard\n",
    "#mode = \"bpmask_pred\"\n",
    "mode = \"warped_clothes_ref\"\n",
    "\n",
    "if mode == \"all\":\n",
    "    algo1_tryon_path = \"../outputs/{}/{}/\".format(algo1, mode) # only all\n",
    "    algo1_tryon_files = sorted(make_dataset(algo1_tryon_path))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "algo2_tryon_path = \"../outputs/{}/{}/\".format(algo2, mode)\n",
    "algo3_tryon_path = \"../outputs/{}/{}/\".format(algo3, mode)\n",
    "algo4_tryon_path = \"../outputs/{}/{}/\".format(algo4, mode)\n",
    "algo5_tryon_path = \"../outputs/{}/{}/\".format(algo5, mode)\n",
    "algo6_tryon_path = \"../outputs/{}/{}/\".format(algo6, mode)\n",
    "\n",
    "# File paths to tryon images\n",
    "#algo1_tryon_files = sorted(make_dataset(algo1_tryon_path))\n",
    "algo2_tryon_files = sorted(make_dataset(algo2_tryon_path))\n",
    "algo3_tryon_files = sorted(make_dataset(algo3_tryon_path))\n",
    "algo4_tryon_files = sorted(make_dataset(algo4_tryon_path))\n",
    "algo5_tryon_files = sorted(make_dataset(algo5_tryon_path))\n",
    "algo6_tryon_files = sorted(make_dataset(algo6_tryon_path))\n",
    "\n",
    "# Path to reference person and cloth images\n",
    "ref_person_path = \"../../datasets/acgpn_data/try_on_testing/\"\n",
    "\n",
    "persons = []\n",
    "clothes = []\n",
    "\n",
    "# for all\n",
    "with open(os.path.join(\"../../datasets/acgpn_data/try_on_testing/test_pairs.txt\"), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        h_name, c_name = line.strip().split()\n",
    "        persons.append(h_name)\n",
    "        clothes.append(c_name)\n",
    "\n",
    "\n",
    "ref_person_paths = [os.path.join(ref_person_path, \"test_img\", x) for x in persons]\n",
    "target_clothes_paths = [os.path.join(ref_person_path, \"test_color\", x) for x in clothes]\n",
    "\n",
    "# GT segs\n",
    "gt_seg = \"../outputs/{}/{}/\".format(\"acgpn_paper\", \"bpmask\")\n",
    "gt_seg_files = sorted(make_dataset(gt_seg))\n",
    "\n",
    "\n",
    "\n",
    "## Robustness test\n",
    "cs_1 = []\n",
    "ps_1 = []\n",
    "vtons_1 = []\n",
    "wrs_1 = []\n",
    "ws_1 = []\n",
    "\n",
    "vtons_2 = []\n",
    "wrs_2 = []\n",
    "ws_2 = []\n",
    "\n",
    "r_fifa = \"../outputs/robustness_random/{}/\".format(\"acgpn_gen\") # acgpn\n",
    "idxs = sorted(os.listdir(r_fifa))\n",
    "for idx in idxs:\n",
    "    files = sorted(make_dataset(os.path.join(r_fifa, idx)))\n",
    "    for f in files:\n",
    "        if \"person\" in f:\n",
    "            ps_1.append(f)\n",
    "        if \"cloth\" in f:\n",
    "            cs_1.append(f)\n",
    "        if \"tryon\" in f:\n",
    "            vtons_1.append(f)\n",
    "        if \"_refined\" in f:\n",
    "            wrs_1.append(f)\n",
    "        if \"warped.\" in f:\n",
    "            ws_1.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c731f-2261-4478-9fac-396f669a8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../outputs/robustness_random/acgpn/.DS_Store\n",
    "!rm ../outputs/robustness_random/fifa/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3abcb-76ff-4ae4-8f93-48c1e0933eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fifa = \"../outputs/robustness_random/{}/\".format(\"fifa_gen\") # fifa\n",
    "idxs = sorted(os.listdir(r_fifa))\n",
    "for idx in idxs:\n",
    "    files = sorted(make_dataset(os.path.join(r_fifa, idx)))\n",
    "    for f in files:\n",
    "        if \"tryon\" in f:\n",
    "            vtons_2.append(f)\n",
    "        if \"_refined\" in f:\n",
    "            wrs_2.append(f)\n",
    "        if \"warped.\" in f:\n",
    "            ws_2.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b1cad-7f43-43e2-bca5-9447408e97db",
   "metadata": {},
   "source": [
    "### Show all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab8325-f33a-45a8-adcc-0b17d37f1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this....\n",
    "# i = 0\n",
    "# for num in range(3):\n",
    "#     visualize(i, reference_person=read_image(ref_person_paths[num]), target_clothes=read_image(target_clothes_paths[num]),\n",
    "#               cpvtonpp=read_image(algo1_tryon_files[num]),\n",
    "#               acgpn=read_image(algo2_tryon_files[num]),\n",
    "#               with_res=read_image(algo3_tryon_files[num]),\n",
    "#               with_all_res=read_image(algo4_tryon_files[num]),\n",
    "#               with_res_msssim=read_image(algo5_tryon_files[num]),\n",
    "#               Ours=read_image(algo6_tryon_files[num]))\n",
    "#     i+=1\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# for num in range(3):\n",
    "#     visualize(i, reference_person=read_image(ref_person_paths[num]), target_clothes=read_image(target_clothes_paths[num]),\n",
    "#               cpvtonpp=read_image(algo1_tryon_files[num]),\n",
    "#               acgpn=read_image(algo2_tryon_files[num]),\n",
    "#               with_res=read_image(algo3_tryon_files[num]),\n",
    "#               with_all_res=read_image(algo4_tryon_files[num]),\n",
    "#               with_res_msssim=read_image(algo5_tryon_files[num]),\n",
    "#               Ours=read_image(algo6_tryon_files[num]))\n",
    "#     i+=1\n",
    "\n",
    "\n",
    "# bpmasks\n",
    "# i = 0\n",
    "# for num in range(500):\n",
    "#     visualize(i, reference_person=read_image(ref_person_paths[num]), target_clothes=read_image(target_clothes_paths[num]),\n",
    "#               acgpn=read_image(algo2_tryon_files[num]),\n",
    "#               with_res=read_image(algo3_tryon_files[num]))\n",
    "#     i+=1\n",
    "\n",
    "# warped refined clothes\n",
    "# i = 0\n",
    "# for num in range(2032):\n",
    "#     visualize(i, target_clothes=read_image(target_clothes_paths[num]),\n",
    "#               wo_inp=read_image(algo3_tryon_files[num]),\n",
    "#               w_inp=read_image(algo6_tryon_files[num]),\n",
    "#              reference_person=read_image(ref_person_paths[num]))\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4559a-694c-40db-a4d1-54e9b1dea2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946edd59-b4f4-4d9f-831a-1d73f36b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis:\n",
    "# good_idxs = [4,12,13,22,28,42,89,95,104,110,\n",
    "#            121,125,126,128,137,168,172,187,\n",
    "#            221,222,251,300,315,318,342,350,383,\n",
    "#           422,439,636,660,\n",
    "#           737,827,919,1012,1024,1025,\n",
    "#           1048,1164,1181,1419,1600,1663,\n",
    "#           1723,1746,1790,1941,1942,1949,\n",
    "#           1961,1970,1980,1983,1986,1988]\n",
    "\n",
    "# tryon idxs\n",
    "good_idxs = [4,12,13,22,28,42,95,104,110,\n",
    "           125,128,168,172,187,\n",
    "           221,222,251,342,350,383,\n",
    "          439,636,660,\n",
    "          737,827,919,1012,1024,1025,\n",
    "          1048,1164,1181,1419,1600,1663,\n",
    "          1723,1746,1790,1941,1942,1949\n",
    "          ,1970,1980,1988]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a46c9-4572-4853-a996-8ca9ecbd42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c401c-9224-42c3-a980-6fdc511a8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complex pose, \n",
    "#texture of clothing, \n",
    "#embroidery of clothing, \n",
    "#retains collar shape of clothing\n",
    "\n",
    "# tryon idxs\n",
    "nums = [95,104,342,\n",
    "       187,1048,1941,\n",
    "       128,827,636,\n",
    "       439,660,1949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebb9ee-464f-480e-9c99-41444094074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fe98b-53de-4422-bacc-a31519eb1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372a9a6-1e8f-40d4-9e5e-4c5ad3246150",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in nums:\n",
    "    print(ref_person_paths[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6e6ab-b91d-495f-b821-0742e913f832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b091d77-7dee-4470-8253-896f2dc8ac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be31acec-d1ab-4288-9dc7-1825001f9b6c",
   "metadata": {},
   "source": [
    "### Plot to compare try-ons with SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2618f-bf59-4145-a76f-d4f2e5098a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums) / 3)\n",
    "cols = 15\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(40, 15), constrained_layout=True)\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(rp1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc1=read_image(target_clothes_paths[nums[v+r]])\n",
    "    a1=read_image(algo1_tryon_files[nums[v+r]])\n",
    "    cpv1 = read_image(algo2_tryon_files[nums[v+r]])\n",
    "    o1=read_image(algo6_tryon_files[nums[v+r]])\n",
    "    \n",
    "    rp2=read_image(ref_person_paths[nums[v+r+1]])\n",
    "    cv2.putText(rp2, str(alphabet_list[v+r+1]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc2=read_image(target_clothes_paths[nums[v+r+1]])\n",
    "    a2=read_image(algo1_tryon_files[nums[v+r+1]])\n",
    "    cpv2 = read_image(algo2_tryon_files[nums[v+r+1]])\n",
    "    o2=read_image(algo6_tryon_files[nums[v+r+1]])\n",
    "    \n",
    "    rp3=read_image(ref_person_paths[nums[v+r+2]])\n",
    "    cv2.putText(rp3, str(alphabet_list[v+r+2]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc3=read_image(target_clothes_paths[nums[v+r+2]])\n",
    "    a3=read_image(algo1_tryon_files[nums[v+r+2]])\n",
    "    cpv3 = read_image(algo2_tryon_files[nums[v+r+2]])\n",
    "    o3=read_image(algo6_tryon_files[nums[v+r+2]])\n",
    "    \n",
    "    v+=2\n",
    "    \n",
    "    images = [rp1, tc1, a1, cpv1, o1, rp2, tc2, a2, cpv2, o2, rp3, tc3, a3, cpv3, o3]\n",
    "    \n",
    "    captions = [\"Reference \\n Person\", \"Target \\n Clothes\", \"CP-VTON+\", \"ACGPN\", \"FIFA (Ours)\",\n",
    "                \"Reference \\n Person\", \"Target \\n Clothes\", \"CP-VTON+\", \"ACGPN\", \"FIFA (Ours)\",\n",
    "                \"Reference \\n Person\", \"Target \\n Clothes\", \"CP-VTON+\", \"ACGPN\", \"FIFA (Ours)\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=40)\n",
    "\n",
    "plt.savefig(\"../outputs/compare_sota.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1df64-b169-43b3-b7e1-7af7ece53399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb1446-eb92-44b7-8064-e4ceb4430601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nums = [4,12,22,28,110,121, 125,168,221,251,300,350,383,737\n",
    "#         ,919,1012,1024,1025,1164,1600, 1633,\n",
    "#         1723,1746,1790,1942,1970, 1980, 1983, 1986, 1988][:16]\n",
    "\n",
    "\n",
    "# Fig 1\n",
    "# fails to preserve texture and embroidery of target clothing -> 1988,350,383,737,1790,919,121,1025\n",
    "# bad in complex pose -> 4, 22, 1024, 1164, 1746\n",
    "# blurry -> 1600, 1970, 1980\n",
    "\n",
    "# Fig 2\n",
    "# unrealistic human skin parts -> 12, 110, 251\n",
    "# keeps old clothing -> 28, 125, 1942, 300\n",
    "# human color -> 1012, 1723\n",
    "# front and black clothing mixed -> 1986, 168, 221,1663,1983\n",
    "\n",
    "\n",
    "#nums = [1988,350,383,737,1790,919,121,1025, 4, 22, 1024, 1164, 1746, 1600, 1970, 1980]\n",
    "nums = [12, 110, 251, 28, 125, 1942, 300, 1012, 1723, 1986, 168, 221,1663,1983]\n",
    "\n",
    "len(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd7638-ed5e-46c1-a1dd-ea34a5a26f7d",
   "metadata": {},
   "source": [
    "## Extensive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a3b88-a042-4a83-a0bf-5873d9a40beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums)/ 2)\n",
    "cols = 12\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(30, 24), constrained_layout=True) # 24 or 27\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(rp1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc1=read_image(target_clothes_paths[nums[v+r]])\n",
    "    a1=read_image(algo1_tryon_files[nums[v+r]])\n",
    "    cpv1 = read_image(algo2_tryon_files[nums[v+r]])\n",
    "    o0=read_image(algo5_tryon_files[nums[v+r]])\n",
    "    o1=read_image(algo6_tryon_files[nums[v+r]])\n",
    "    \n",
    "    rp2=read_image(ref_person_paths[nums[v+r+1]])\n",
    "    cv2.putText(rp2, str(alphabet_list[v+r+1]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc2=read_image(target_clothes_paths[nums[v+r+1]])\n",
    "    a2=read_image(algo1_tryon_files[nums[v+r+1]])\n",
    "    cpv2 = read_image(algo2_tryon_files[nums[v+r+1]])\n",
    "    o00=read_image(algo5_tryon_files[nums[v+r+1]])\n",
    "    o2=read_image(algo6_tryon_files[nums[v+r+1]])\n",
    "    \n",
    "    v+=1\n",
    "    \n",
    "    images = [rp1, tc1, a1, cpv1, o0, o1, rp2, tc2, a2, cpv2, o00, o2]\n",
    "    \n",
    "    captions = [\"Reference \\n Person\", \"Target \\n Clothes\", \"CP-VTON+\", \"ACGPN\", \"FIFA (Ours) \\n (w/o MCM)\", \"FIFA (Ours)\",\n",
    "               \"Reference \\n Person\", \"Target \\n Clothes\", \"CP-VTON+\", \"ACGPN\", \"FIFA (Ours) \\n (w/o MCM)\", \"FIFA (Ours)\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=30)\n",
    "\n",
    "plt.savefig(\"../outputs/compare_sota_extensive2.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbcd632-f166-46c9-984c-8faee7a286d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e65a990-7a07-407f-88b5-9e629b97da4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4f664-4da0-4bf5-90ad-e28a56636423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6a77f20-dbbb-4d2a-a8b9-4caf8f8dc41d",
   "metadata": {},
   "source": [
    "## Robustness test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282f78a-cbf8-4b07-b916-27670d8fe0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs_1 = []\n",
    "# ps_1 = []\n",
    "# vtons_1 = []\n",
    "# wrs_1 = []\n",
    "# ws_1 = []\n",
    "\n",
    "# vtons_2 = []\n",
    "# wrs_2 = []\n",
    "# ws_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829b404-3ddb-4632-b28f-faaf8c37dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [x for x in range(10)]\n",
    "random.shuffle(nums)\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a23305-2a28-4063-836f-2661220ca264",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums)/ 2)\n",
    "cols = 8\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(30, 26), constrained_layout=True)\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image_(ps_1[nums[v+r]])\n",
    "    tc1=read_image_(cs_1[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(tc1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    a1=read_image_(vtons_1[nums[v+r]])\n",
    "    cpv1 = read_image_(vtons_2[nums[v+r]])\n",
    "    \n",
    "    rp2=read_image_(ps_1[nums[v+r+1]])\n",
    "    tc2=read_image_(cs_1[nums[v+r+1]])\n",
    "    cv2.putText(tc2, str(alphabet_list[v+r+1]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    a2=read_image_(vtons_1[nums[v+r+1]])\n",
    "    cpv2 = read_image_(vtons_2[nums[v+r+1]])\n",
    "    \n",
    "    v+=1\n",
    "    \n",
    "    images = [tc1, rp1, a1, cpv1, tc2, rp2, a2, cpv2]\n",
    "    \n",
    "    captions = [\"Target \\n Clothes\", \"Reference \\n Person\", \"ACGPN\", \"FIFA (Ours)\",\n",
    "               \"Target \\n Clothes\", \"Reference \\n Person\", \"ACGPN\", \"FIFA (Ours)\",]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=45)\n",
    "\n",
    "plt.savefig(\"../outputs/robustness_tryons_random_viton.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac187ae3-5e19-4ab7-8b98-58c34307f64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdb113-78ae-4cfc-b795-11150a7d91aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964716f-fb30-4ce9-ab1b-6c17d3c7fb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ae088-300d-459e-83a9-e572a38a400d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc68b20-ea08-4880-9d32-db62c8f7aad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2f4a7-954f-4f40-a39e-5af52ecfd750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a534f-9075-48cb-9e4e-f758ea8d1d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aa015ae-7c97-4e86-ad65-767235df4071",
   "metadata": {},
   "source": [
    "### Plot for ablation 1 (ablation for res, loss, inpaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0f872-10b9-4aa7-a470-9e0bc526c79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nums = [1181, 1419]\n",
    "\n",
    "# res blocks -> RBs \n",
    "# multi-scale strutural constraint -> MSS\n",
    "# Masked Clothing Modeling -> MCM objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e25919-c656-4509-9b3f-47a805d075e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums))\n",
    "cols = 7\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(37, 15), constrained_layout=True)\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    tc1=read_image(target_clothes_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(tc1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    a1=read_image(algo1_tryon_files[nums[v+r]])\n",
    "    cpv1 = read_image(algo2_tryon_files[nums[v+r]])\n",
    "    o1=read_image(algo3_tryon_files[nums[v+r]])\n",
    "    o2=read_image(algo5_tryon_files[nums[v+r]])\n",
    "    o3=read_image(algo6_tryon_files[nums[v+r]])\n",
    "    \n",
    "    images = [tc1, rp1, a1, cpv1, o1, o2, o3]\n",
    "    \n",
    "    captions = [\"Target \\n Clothes\", \"Reference \\n Person\", \"CP-VTON+\", \"ACGPN\", \"FIFA \\n w/ RBs \",\n",
    "                \"FIFA \\n w/ RBs + MSC\", \"FIFA \\n w/ RBs + MSC + MCM\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=40)\n",
    "\n",
    "plt.savefig(\"../outputs/ablation_1.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1fed9-23ec-4376-8992-4d44310ca604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea121f-0ccd-490d-b2d0-16a37c0b2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca4f169a-3d56-44ad-8779-2225b0c0ed4c",
   "metadata": {},
   "source": [
    "### Plot for abl 2 (w/o and with res)\n",
    "\n",
    "mode should be \"bpmask_pred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bc760-6c8d-493b-93be-f067cf1fd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [39, 57, 133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408833c-f829-469b-88c6-d7cd58003e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums))\n",
    "cols = 4\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(20, 20), constrained_layout=True)\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    tc1=read_image(target_clothes_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(tc1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    a1 = read_image(algo2_tryon_files[nums[v+r]])\n",
    "    a2=read_image(algo3_tryon_files[nums[v+r]])\n",
    "    \n",
    "    images = [tc1, rp1, a1, a2]\n",
    "    \n",
    "    captions = [\"Target \\n Clothes\", \"Reference \\n Person\", \" FIFA (Ours) \\n w/o RBs\", \" FIFA (Ours) \\n w/ RBs\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=30)\n",
    "\n",
    "plt.savefig(\"../outputs/ablation_2_res.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95abc90-5795-4090-bd73-419e661525ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe6d65-ac53-4d79-9616-a5d2959aa817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f51268-bf35-42d2-b9fa-2987cdf9d991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad016c9-0c03-4bab-9f4e-25a60f86bfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6bc8bcb-ee34-490d-98be-d4607173d791",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot for ablation 3 (w/o and w inpaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f191a1a-e324-4642-8d7c-2c8f6d86af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve logo a,b\n",
    "# complex pose c\n",
    "# synthesize cloth in non-target body parts a,b, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40361ea1-ce65-40bd-b30d-cd059536a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [938, 998, 357, 59] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03d60f-4b40-4ce9-b340-dea51a721963",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums)/ 2)\n",
    "cols = 8\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(27, 10), constrained_layout=True)\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    tc1=read_image(target_clothes_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(tc1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    a1=read_image(algo3_tryon_files[nums[v+r]])\n",
    "    cpv1 = read_image(algo6_tryon_files[nums[v+r]])\n",
    "    \n",
    "    rp2=read_image(ref_person_paths[nums[v+r+1]])\n",
    "    tc2=read_image(target_clothes_paths[nums[v+r+1]])\n",
    "    cv2.putText(tc2, str(alphabet_list[v+r+1]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    a2=read_image(algo3_tryon_files[nums[v+r+1]])\n",
    "    cpv2 = read_image(algo6_tryon_files[nums[v+r+1]])\n",
    "    \n",
    "    v+=1\n",
    "    \n",
    "    images = [tc1, rp1, a1, cpv1, tc2, rp2, a2, cpv2]\n",
    "    \n",
    "    captions = [\"Target \\n Clothes\", \"Reference \\n Person\", \"FIFA (Ours) \\n (w/o MCM)\", \"FIFA (Ours) \\n (w/ MCM)\",\n",
    "               \"Target \\n Clothes\", \"Reference \\n Person\", \"FIFA (Ours) \\n (w/o MCM)\", \"FIFA (Ours) \\n (w/ MCM)\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=35)\n",
    "\n",
    "plt.savefig(\"../outputs/abl_compare_warps.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e04a61-c045-47a3-8c82-c8dd9152002e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4888c7-f7bf-46bc-83cd-88d0635c71e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0e57764-415c-49bf-917e-7beb37b63526",
   "metadata": {},
   "source": [
    "### Plot extensive warps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5154f6d-8c66-4d13-b6a1-a3a440ec2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nums= [5,11,23,59,66,68,80,218,243,294,315,381,414,512,522,652,684,864,874,1000][:14]\n",
    "nums= [11,23,59,66,68,294,5,315,381,512,684,864,874,1000]\n",
    "len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7594a2a-8a8e-454f-913f-25ed6a8ed2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums)/ 2)\n",
    "cols = 8\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(26, 31), constrained_layout=True)\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    tc1=read_image(target_clothes_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(tc1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    a1=read_image(algo3_tryon_files[nums[v+r]])\n",
    "    cpv1 = read_image(algo6_tryon_files[nums[v+r]])\n",
    "    \n",
    "    rp2=read_image(ref_person_paths[nums[v+r+1]])\n",
    "    tc2=read_image(target_clothes_paths[nums[v+r+1]])\n",
    "    cv2.putText(tc2, str(alphabet_list[v+r+1]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    a2=read_image(algo3_tryon_files[nums[v+r+1]])\n",
    "    cpv2 = read_image(algo6_tryon_files[nums[v+r+1]])\n",
    "    \n",
    "    v+=1\n",
    "    \n",
    "    images = [tc1, rp1, a1, cpv1, tc2, rp2, a2, cpv2]\n",
    "    \n",
    "    captions = [\"Reference \\n Person\", \"Target \\n Clothes\", \"FIFA (Ours) \\n (w/o MCM)\", \"FIFA (Ours) \\n (w/ MCM)\",\n",
    "               \"Reference \\n Person\", \"Target \\n Clothes\", \"FIFA (Ours) \\n (w/o MCM)\", \"FIFA (Ours) \\n (w/ MCM)\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=30)\n",
    "\n",
    "plt.savefig(\"../outputs/warps_ext.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7e6b5-b06e-4cd5-b1de-4dedba10026d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3c89b-b0c4-4db6-803c-bf83aa4bc3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3eb3c-d4ac-4fbd-92cf-2b26fa117a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1595f4-556c-47f5-8b0c-e790255ccd92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942ea33-715b-4c02-9a69-a63c790c6758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2df0a-dfa5-4685-b230-434e982cf904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54b0ef-0925-406b-932d-5ada52ab5d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0a174-85b4-4b73-b7e1-20e93c75c884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca5bb5-6940-466b-89ff-ccc490d3db91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "855c928b-8e66-49eb-8e84-b55ecfaf9f31",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d614df-4022-41ac-84b1-94432e17eece",
   "metadata": {},
   "source": [
    "## Vis warped clothes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c935a3-9836-4e41-b357-5881f61b47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for num in range(5):\n",
    "#     visualize(i, target_cloth=read_image(cloth_files[num]), warped_by_stn=read_image(wcr_files[num]),\n",
    "#               warp_refine=read_image(wcr_ref_files[num]),\n",
    "#              reference_person=read_image(ref_person_paths[num]))\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15a1e4-ed18-4428-ad19-e8b27b499fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81571755-61cb-4302-a389-56b314b54ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047a11a-0a28-48ad-87d5-8dfec102634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_path = \"../outputs/{}/{}/\".format(algo1, \"clothes\")\n",
    "wcr_ref_path1 = \"../outputs/{}/{}/\".format(algo1, \"warped_clothes_ref\")\n",
    "wcr_ref_path2 = \"../outputs/{}/{}/\".format(algo2, \"warped_clothes_ref\")\n",
    "\n",
    "cloth_files = sorted(make_dataset(cloth_path))\n",
    "wcr1 = sorted(make_dataset(wcr_ref_path1))\n",
    "wcr2 = sorted(make_dataset(wcr_ref_path2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9baa487-55cd-469d-937c-a732390f812d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced487e-2a18-4b46-ae6f-48ca02a76777",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for num in range(2032):\n",
    "    visualize(i, target_cloth=read_image(cloth_files[num]), resunet=read_image(wcr1[num]),\n",
    "              ssl=read_image(wcr2[num]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbd01b-8f2f-4fc2-9e50-64264b457f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f251c-ca5a-4b2e-993e-0da0be7a1387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a05332-3aa5-4870-a1ee-5dfca81ce035",
   "metadata": {},
   "source": [
    "### Vis seg masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c81a74-302b-451d-a18e-eb2dfdd06851",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_seg = \"../outputs/{}/{}/\".format(\"segs\", \"bpmask\")\n",
    "a1_seg = \"../outputs/{}/{}/\".format(\"segs\", \"bpmask_pred_unet\")\n",
    "a2_seg = \"../outputs/{}/{}/\".format(\"segs\", \"bpmask_pred\")\n",
    "\n",
    "gt_seg_files = sorted(make_dataset(gt_seg))\n",
    "a1_seg_files = sorted(make_dataset(a1_seg))\n",
    "a2_seg_files = sorted(make_dataset(a2_seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18433054-f262-427a-b405-b0059f555b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc9ff5-3622-4b49-bd51-8c0e8480e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "nums = [0, 2, 6, 34, 69, 510, 853]\n",
    "for num in nums:\n",
    "    visualize(i, ground_seg=read_image(gt_seg_files[num]), unet_seg=read_image(a1_seg_files[num]),\n",
    "              resunet_seg=read_image(a2_seg_files[num]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc144e-2bc1-41bf-93ab-cbfb628111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 2, 6, 34, 69, 510] # 853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d796e-a198-4dc7-9881-c1997b5cb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums) / 3)\n",
    "cols = 12\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(42, 10), constrained_layout=True)\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(rp1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc1=read_image(gt_seg_files[nums[v+r]])\n",
    "    a1_seg=read_image(a1_seg_files[nums[v+r]])\n",
    "    a2_seg = read_image(a2_seg_files[nums[v+r]])\n",
    "    \n",
    "    rp2=read_image(ref_person_paths[nums[v+r+1]])\n",
    "    cv2.putText(rp2, str(alphabet_list[v+r+1]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc2=read_image(gt_seg_files[nums[v+r+1]])\n",
    "    a21_seg=read_image(a1_seg_files[nums[v+r+1]])\n",
    "    a22_seg = read_image(a2_seg_files[nums[v+r+1]])\n",
    "    \n",
    "    rp3=read_image(ref_person_paths[nums[v+r+2]])\n",
    "    cv2.putText(rp3, str(alphabet_list[v+r+2]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc3=read_image(gt_seg_files[nums[v+r+2]])\n",
    "    a23_seg=read_image(a1_seg_files[nums[v+r+2]])\n",
    "    a223_seg = read_image(a2_seg_files[nums[v+r+2]])\n",
    "    \n",
    "    v+=2\n",
    "    \n",
    "    images = [rp1, tc1, a1_seg, a2_seg, rp2, tc2, a21_seg, a22_seg, rp3, tc3, a23_seg, a223_seg]\n",
    "    \n",
    "    \n",
    "    captions = [\"Reference \\n Person\", \"Ground Truth \\n Body Part Mask\", \"w/o \\n residual units\", \"with \\n residual units\",\n",
    "                \"Reference \\n Person\", \"Ground Truth \\n Body Part Mask\", \"w/o \\nresidual units\", \"with \\n residual units\",\n",
    "               \"Reference \\n Person\", \"Ground Truth \\n Body Part Mask\", \"w/o  \\n residual units\", \"with  \\n residual units\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal')\n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=35)\n",
    "\n",
    "plt.savefig(\"../outputs/vis_mask.png\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624612f-6340-4d32-96de-97855949fee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba96ba8c-df17-4b6f-a2e9-fa5019510715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddcee4c9-eb42-4ed7-83c4-c0887720061c",
   "metadata": {},
   "source": [
    "### Show masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2148065-9304-46ba-9d6b-9a654de52eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nums = np.array([6, 82, 17, 18, 23, 28, 57, 59, 67, 71, 120, 169, 239, 305, 307, 507, 1868, 1961, 1981, 2012])[-12:]\n",
    "# nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3541d-9c6c-46b7-8e49-364c8a5450c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for num in nums:\n",
    "#     visualize(i, reference_person=read_image(ref_person_paths[num]),\n",
    "#               Clothing_Region_GT=read_image(gt_wcr_files[num])[:,:,0], \n",
    "#               Unet=read_image(algo1_wcr_path[num])[:,:,0], resunet=read_image(algo2_wcr_path[num])[:,:,0])\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057779cf-8348-476a-a9bf-cf07da2ee9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc9e0d-50ad-4ffe-9e97-524795c680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using npstack\n",
    "\n",
    "# arrs = []\n",
    "# for refp, clt, gtwcr, a1wcr, a2wcr, a1, a2 in zip(ref_person_paths[:slc], target_clothes_paths[:3], \n",
    "#                   gt_wcr_files[:slc], algo1_wcr_path[:slc], algo2_wcr_path[:slc], algo1_tryon_files[:slc],\n",
    "#                   algo2_tryon_files[:slc]):\n",
    "    \n",
    "#     person=read_image(refp)\n",
    "#     cloth=read_image(clt)\n",
    "\n",
    "#     wcr=read_image(gtwcr) \n",
    "#     #wcr= np.where(wcr==127, 0, wcr)\n",
    "\n",
    "#     wcr_acgpn=read_image(a1wcr) \n",
    "#     #wcr_acgpn= np.where(wcr_acgpn==127, 0, wcr_acgpn)\n",
    "\n",
    "#     wcr_ours=read_image(a2wcr)\n",
    "#     #wcr_ours= np.where(wcr_ours==127, 0, wcr_ours)\n",
    "\n",
    "#     acgpn=read_image(a1)\n",
    "#     ours=read_image(a2)\n",
    "    \n",
    "#     out = np.hstack((person, cloth, wcr, wcr_acgpn, wcr_ours, acgpn, ours))\n",
    "#     #out = np.pad(out, pad_width=1, mode='constant', constant_values=0)\n",
    "#     arrs.append(out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318b380-5c32-48fc-b498-caff539de600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_output = np.vstack((x for x in arrs))\n",
    "# final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac83dd-b464-4cee-b6e7-ee9908441843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18, 16))\n",
    "# plt.axis(\"off\")\n",
    "# plt.imshow(final_output, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35681b17-f34c-415d-993b-1e992ec3bbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8850ec2-8244-451e-b115-575860e55268",
   "metadata": {},
   "source": [
    "### Plot images with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00da3d-afda-4953-92cd-9ad593a1ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nums = np.random.randint(0, 2032, 5)\n",
    "# nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbe64f-0dc7-4931-ba0c-f5278982fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nums = [i for i in range(5)] # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9e854-682c-4daa-9832-ca8d11e999ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = len(nums)\n",
    "# cols = 7\n",
    "# fig, axarr = plt.subplots(rows, cols, figsize=(40, 38), constrained_layout=True)\n",
    "\n",
    "# for r in range(rows):\n",
    "#     reference_person=read_image(ref_person_paths[nums[r]])\n",
    "#     target_clothes=read_image(target_clothes_paths[nums[r]])\n",
    "#     Clothing_Region_GT=read_image(gt_wcr_files[nums[r]])[:,:,0]\n",
    "#     Unet=read_image(algo1_wcr_path[nums[r]])[:,:,0]\n",
    "#     resunet=read_image(algo2_wcr_path[nums[r]])[:,:,0]\n",
    "#     ACGPN=read_image(algo1_tryon_files[nums[r]])\n",
    "#     Ours=read_image(algo2_tryon_files[nums[r]])\n",
    "    \n",
    "#     images = [reference_person, target_clothes, Clothing_Region_GT, Unet, resunet, ACGPN, Ours]\n",
    "#     captions = [\"Reference \\n Person\", \"Target \\n Clothes\", \"Clothing Region \\n Ground Truth\", \"U-Net\", \"Res U-Net\", \"ACGPN\", \"Ours\"]\n",
    "    \n",
    "#     for c in range(cols):\n",
    "#         axarr[r, c].imshow(images[c], cmap='gray')\n",
    "#         axarr[r, c].axis(\"off\")\n",
    "#         axarr[r, c].set_aspect('equal')\n",
    "#         if r==0:\n",
    "#             axarr[r, c].set_title(captions[c], fontsize=50)\n",
    "\n",
    "# plt.savefig(\"../outputs/visualization_all.png\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b955beb5-249f-46e8-ac11-e12ab7d9afe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c1eedc-5323-43de-acce-40d84914dbe2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tryon images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5064b-4438-4ba5-9d7c-33cd87ac091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = np.random.randint(0, 2032, 12)\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c86bc-1243-41ad-87be-5cc4aded31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acgpn and res acgpn\n",
    "#nums = np.array([6, 82, 17, 18, 23, 28, 57, 59, 67, 71, 120, 169, 239, 305, 307, 507, 1868, 1961, 1981, 2012])[-12:]\n",
    "\n",
    "# With acgpn, cpvton+, res acgpn\n",
    "#nums = np.array([5,6,9,18,59,172,189,190,275,277,322,566,743,1024,1417,1954,2012, 2031])[:12]\n",
    "nums = np.array([2031,2012,9,18,743,1417,189,190,275,277,322,566,743,1024,1417,1954,2012, 2031])[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568599e2-f65d-4b06-b016-8d1f941afc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1ba5d-cf07-41fe-8ab6-9f6e9d938306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nums = [i for i in range(12)]\n",
    "# nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ebe8f-74b3-4e71-b8c8-d0ab1928957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(len(nums) / 3)\n",
    "cols = 15\n",
    "fig, axarr = plt.subplots(rows, cols, figsize=(40, 15), constrained_layout=True)\n",
    "\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)\n",
    "\n",
    "v = 0\n",
    "for r in range(rows):\n",
    "    rp1=read_image(ref_person_paths[nums[v+r]])\n",
    "    w,h = (1,25)\n",
    "    fs = 1.0\n",
    "    color = (0,0,0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX #FONT_HERSHEY_DUPLEX  #press tab for different operations\n",
    "    cv2.putText(rp1, str(alphabet_list[v+r]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc1=read_image(target_clothes_paths[nums[v+r]])\n",
    "    a1=read_image(algo1_tryon_files[nums[v+r]])\n",
    "    cpv1 = read_image(algo3_tryon_files[nums[v+r]])\n",
    "    o1=read_image(algo2_tryon_files[nums[v+r]])\n",
    "    \n",
    "    rp2=read_image(ref_person_paths[nums[v+r+1]])\n",
    "    cv2.putText(rp2, str(alphabet_list[v+r+1]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc2=read_image(target_clothes_paths[nums[v+r+1]])\n",
    "    a2=read_image(algo1_tryon_files[nums[v+r+1]])\n",
    "    cpv2 = read_image(algo3_tryon_files[nums[v+r+1]])\n",
    "    o2=read_image(algo2_tryon_files[nums[v+r+1]])\n",
    "    \n",
    "    rp3=read_image(ref_person_paths[nums[v+r+2]])\n",
    "    cv2.putText(rp3, str(alphabet_list[v+r+2]), (w,h), font, fs, color, 1, cv2.LINE_AA)\n",
    "    tc3=read_image(target_clothes_paths[nums[v+r+2]])\n",
    "    a3=read_image(algo1_tryon_files[nums[v+r+2]])\n",
    "    cpv3 = read_image(algo3_tryon_files[nums[v+r+2]])\n",
    "    o3=read_image(algo2_tryon_files[nums[v+r+2]])\n",
    "    \n",
    "    v+=2\n",
    "    \n",
    "    images = [rp1, tc1, a1, cpv1, o1, rp2, tc2, a2, cpv2, o2, rp3, tc3, a3, cpv3, o3]\n",
    "    \n",
    "    captions = [\"Reference \\n Person\", \"Target \\n Clothes\", \"ACGPN\", \"CP-VTON+\", \"Ours\",\n",
    "                \"Reference \\n Person\", \"Target \\n Clothes\", \"ACGPN\", \"CP-VTON+\", \"Ours\",\n",
    "                \"Reference \\n Person\", \"Target \\n Clothes\", \"ACGPN\", \"CP-VTON+\", \"Ours\"]\n",
    "    \n",
    "    for c in range(cols):\n",
    "        axarr[r, c].imshow(images[c], cmap='gray')\n",
    "        axarr[r, c].axis(\"off\")\n",
    "        axarr[r, c].set_aspect('equal') \n",
    "        if r==0:\n",
    "            axarr[r, c].set_title(captions[c], fontsize=40)\n",
    "\n",
    "plt.savefig(\"../outputs/visualization_tryons.png\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6e12f-5353-4d68-b9e5-554d700924bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacb636-7a84-4b31-905a-bde4bc306259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
