{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85066f14-24cf-4596-827d-d1ad83fb049c",
   "metadata": {},
   "source": [
    "## Test config on DecaVTON dataset\n",
    "\n",
    "Computes SSIM and FID scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f59d4-2cfb-4a40-9562-3d54f5c87d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c27a4a-2cd5-4e55-ac51-848259cb2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "sys.path.insert(0,\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fa7a1-4b78-455e-8616-2e47beddc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "\n",
    "import pytorch_ssim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ['PYTHONHASHSEED'] = str(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84dc47-d388-4fa6-af70-4d10520739d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/G1G2')\n",
    "SIZE=320\n",
    "NC=14\n",
    "\n",
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "\n",
    "    f = dir.split('/')[-1].split('_')[-1]\n",
    "    #print (dir, f)\n",
    "    dirs= os.listdir(dir)\n",
    "    for img in dirs:\n",
    "\n",
    "        path = os.path.join(dir, img)\n",
    "        #print(path)\n",
    "        images.append(path)\n",
    "    return images\n",
    "\n",
    "def read_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #image = cv2.resize(image, (320, 512))\n",
    "    return image\n",
    "\n",
    "def generate_label_plain(inputs):\n",
    "    size = inputs.size()\n",
    "    pred_batch = []\n",
    "    for input in inputs:\n",
    "        input = input.view(1, NC, 256,192)\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_batch = pred_batch.view(size[0], 1, 256,192)\n",
    "\n",
    "    return label_batch\n",
    "\n",
    "def generate_label_color(inputs):\n",
    "    label_batch = []\n",
    "    for i in range(len(inputs)):\n",
    "        label_batch.append(util.tensor2label(inputs[i], opt.label_nc))\n",
    "    label_batch = np.array(label_batch)\n",
    "    label_batch = label_batch * 2 - 1\n",
    "    input_label = torch.from_numpy(label_batch)\n",
    "\n",
    "    return input_label\n",
    "def complete_compose(img,mask,label):\n",
    "    label=label.cpu().numpy()\n",
    "    M_f=label>0\n",
    "    M_f=M_f.astype(np.int)\n",
    "    M_f=torch.FloatTensor(M_f).cuda()\n",
    "    masked_img=img*(1-mask)\n",
    "    M_c=(1-mask.cuda())*M_f\n",
    "    M_c=M_c+torch.zeros(img.shape).cuda()##broadcasting\n",
    "    return masked_img,M_c,M_f\n",
    "\n",
    "def compose(label,mask,color_mask,edge,color,noise):\n",
    "    # check=check>0\n",
    "    # print(check)\n",
    "    masked_label=label*(1-mask)\n",
    "    masked_edge=mask*edge\n",
    "    masked_color_strokes=mask*(1-color_mask)*color\n",
    "    masked_noise=mask*noise\n",
    "    return masked_label,masked_edge,masked_color_strokes,masked_noise\n",
    "def changearm(old_label):\n",
    "    label=old_label\n",
    "    arm1=torch.FloatTensor((data['label'].cpu().numpy()==11).astype(np.int))\n",
    "    arm2=torch.FloatTensor((data['label'].cpu().numpy()==13).astype(np.int))\n",
    "    noise=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.int))\n",
    "    label=label*(1-arm1)+arm1*4\n",
    "    label=label*(1-arm2)+arm2*4\n",
    "    label=label*(1-noise)+noise*4\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beec7f2-e1c7-49cc-a990-d29dadf24ead",
   "metadata": {},
   "source": [
    "## Select configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3cedc-8d0e-41be-93e9-02684083809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load models\n",
    "exp_name = \"decavton_fifa_wo_fab\" #\"decavton_fifa_wo_fab\", \"eccv_vton\"\n",
    "model_dir = \"../../train_src/checkpoints/\"\n",
    "\n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "opt.load_pretrain = model_dir+exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a1cc4-e17e-4e4c-bbfd-ba4af3179181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test data\n",
    "\n",
    "opt.dataroot = \"../../datasets/decathlon_data/decavtonv2_test/\"\n",
    "opt.datapairs = \"test_pairs_random.txt\" # test_pairs_random.txt\n",
    "category = \"all\"\n",
    "\n",
    "# for all use test_pairs_random\n",
    "# for all_same use test_pairs\n",
    "\n",
    "# Intermediate outputs\n",
    "bp_mask = \"bpmask\"\n",
    "bp_mask_pred = \"bpmask_pred\"\n",
    "wcr_mask = \"wcrmask\"\n",
    "gt_clothes_mask = \"gt_clothes_mask\"\n",
    "warped_clothes = \"warped_clothes\"\n",
    "warped_clothes_ref = \"warped_clothes_ref\"\n",
    "clothes = \"clothes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72939acf-271f-4178-94ab-641c11393e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to tryon\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, category),exist_ok=True)\n",
    "\n",
    "# os.makedirs('../outputs/{}/{}'.format(exp_name, \"easy_imgs\"),exist_ok=True)\n",
    "# os.makedirs('../outputs/{}/{}'.format(exp_name, \"medium_imgs\"),exist_ok=True)\n",
    "# os.makedirs('../outputs/{}/{}'.format(exp_name, \"hard_imgs\"),exist_ok=True)\n",
    "\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, bp_mask),exist_ok=True)\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, wcr_mask),exist_ok=True)\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, gt_clothes_mask),exist_ok=True)\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, warped_clothes),exist_ok=True)\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, warped_clothes_ref),exist_ok=True)\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, clothes),exist_ok=True)\n",
    "os.makedirs('../outputs/{}/{}'.format(exp_name, bp_mask_pred), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd6928-c5c4-4625-a603-89320bcb040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "# Check models used\n",
    "print(opt.load_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb772e4-a823-4a60-aa43-2b734fa0c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df327ac-e988-4a12-912c-7cc09787187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb4cf1-84c2-438e-b0fa-c4da4e95d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('# Inference images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486a158-e0bd-4d19-b4c4-fb4e7ba130e3",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96712e78-2fc0-419a-a7e9-0d607cb8db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a19c9-76ce-403c-ae23-57c29c27b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ecfbbf-2637-498a-881a-bcfee7e6f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5052b4-b166-4d86-a9bc-ab8051932b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch, opt.niter + opt.niter_decay + 1\n",
    "\n",
    "step = 0 \n",
    "ssims = []\n",
    "\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "        \n",
    "    # iterate over the dataset\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        #save_fake = total_steps % opt.display_freq == display_delta\n",
    "        save_fake = True\n",
    "\n",
    "        ##add gaussian noise channel\n",
    "        ## wash the label\n",
    "        t_mask = torch.FloatTensor((data['label'].cpu().numpy() == 7).astype(np.float))\n",
    "        #\n",
    "        # data['label'] = data['label'] * (1 - t_mask) + t_mask * 4\n",
    "        mask_clothes = torch.FloatTensor((data['label'].cpu().numpy() == 4).astype(np.int))\n",
    "        mask_fore = torch.FloatTensor((data['label'].cpu().numpy() > 0).astype(np.int))\n",
    "        img = data['image'].float().cuda()\n",
    "        img_fore = data['image'] * mask_fore\n",
    "        img_fore_wc = img_fore * mask_fore\n",
    "        all_clothes_label = changearm(data['label'])\n",
    "        \n",
    "        \n",
    "#         ## Fore debugging\n",
    "#         def to_img(ten):\n",
    "#             ten =(ten[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "#             ten=(ten*255).astype(np.uint8)\n",
    "#             #ten=cv2.cvtColor(ten,cv2.COLOR_RGB2BGR)\n",
    "#             return ten\n",
    "        \n",
    "#         img_t = to_img(img_fore)\n",
    "#         import ipdb; ipdb.set_trace()\n",
    "#         #######################\n",
    "        \n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        \n",
    "        \n",
    "        # gt_clothes_mask - ground truth cloth mask\n",
    "        losses, fake_image, real_image, input_label,L1_loss,style_loss,clothes_mask,CE_loss,rgb,alpha, gt_clothes_mask, warp_tcw, warp_tcr, bpmask_pred = model(Variable(data['label'].cuda()),\n",
    "                                                                                                             Variable(data['edge'].cuda()),\n",
    "                                                                                                             Variable(img_fore.cuda()),\n",
    "                                                                                                             Variable(mask_clothes.cuda()),\n",
    "                                                                                                             Variable(data['color'].cuda()),\n",
    "                                                                                                             Variable(all_clothes_label.cuda()),\n",
    "                                                                                                             Variable(data['image'].cuda()),\n",
    "                                                                                                             Variable(data['pose'].cuda()) ,\n",
    "                                                                                                             Variable(data['image'].cuda()) ,\n",
    "                                                                                                             Variable(mask_fore.cuda()))\n",
    "                                            \n",
    "        \n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN']+torch.mean(CE_loss)#loss_dict.get('G_GAN_Feat',0)+torch.mean(L1_loss)+loss_dict.get('G_VGG',0)\n",
    "\n",
    "        writer.add_scalar('loss_d', loss_D, step)\n",
    "        writer.add_scalar('loss_g', loss_G, step)\n",
    "        writer.add_scalar('loss_CE', torch.mean(CE_loss), step)\n",
    "        writer.add_scalar('loss_g_gan', loss_dict['G_GAN'], step)\n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "        \n",
    "        ### display output images\n",
    "        a = generate_label_color(generate_label_plain(input_label)).float().cuda()\n",
    "        bpmask_pred_tensor = generate_label_color(generate_label_plain(bpmask_pred)).float().cuda()\n",
    "        b = real_image.float().cuda()\n",
    "        c = fake_image.float().cuda()\n",
    "        d=torch.cat([clothes_mask,clothes_mask,clothes_mask],1)\n",
    "        combine = torch.cat([a[0],d[0],b[0],c[0],rgb[0]], 2).squeeze()\n",
    "        # combine=c[0].squeeze()\n",
    "        cv_img=(combine.permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "        \n",
    "        \n",
    "        # For debug\n",
    "        def to_img(ten):\n",
    "            ten =(ten[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "            ten=(ten*255).astype(np.uint8)\n",
    "            #ten=cv2.cvtColor(ten,cv2.COLOR_RGB2BGR)\n",
    "            return ten\n",
    "        \n",
    "        #ttt = to_img(bpmask_pred_tensor)\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        \n",
    "        if step % 1 == 0:\n",
    "            writer.add_image('combine', (combine.data + 1) / 2.0, step)\n",
    "            rgb=(cv_img*255).astype(np.uint8)\n",
    "            bgr=cv2.cvtColor(rgb,cv2.COLOR_RGB2BGR)\n",
    "            n=str(step)+'.jpg'\n",
    "            \n",
    "            #cv2.imwrite('../samples/'+exp_name+'/'+data['name'][0],bgr)\n",
    "            \n",
    "            #########################################\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            \n",
    "#             # Save clothes types\n",
    "#             imgg =(img[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "#             imgg=(imgg*255).astype(np.uint8)\n",
    "#             imgg=cv2.cvtColor(imgg,cv2.COLOR_RGB2BGR)\n",
    "#             cv2.imwrite('../outputs/'+exp_name+'/'+\"hard_imgs\"+'/'+data['name'][0],imgg)\n",
    "            \n",
    "            \n",
    "            # Save tryon images\n",
    "            fake_i =(fake_image[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "            fake_i=(fake_i*255).astype(np.uint8)\n",
    "            fake_i=cv2.cvtColor(fake_i,cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            cv2.imwrite('../outputs/'+exp_name+'/'+category+'/'+data['name'][0],fake_i)\n",
    "            #########################################\n",
    "            \n",
    "            if category == \"all\":\n",
    "                # Save body part segmentations\n",
    "                seg =(a[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                seg=(seg*255).astype(np.uint8)\n",
    "                seg=cv2.cvtColor(seg,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/bpmask/'+data['name'][0],seg)\n",
    "                \n",
    "                # Save body part segmentations predictions\n",
    "                seg_pred =(bpmask_pred_tensor[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                seg_pred=(seg_pred*255).astype(np.uint8)\n",
    "                seg_pred=cv2.cvtColor(seg_pred,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/bpmask_pred/'+data['name'][0],seg_pred)\n",
    "                \n",
    "                # Save warped cloth region segmentations\n",
    "                cmask =(clothes_mask[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                cmask=(cmask*255).astype(np.uint8)\n",
    "                cmask=cv2.cvtColor(cmask,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/wcrmask/'+data['name'][0],cmask)\n",
    "                \n",
    "                # Save gt segmentations\n",
    "                gt_cmask =(gt_clothes_mask[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                gt_cmask=(gt_cmask*255).astype(np.uint8)\n",
    "                gt_cmask=cv2.cvtColor(gt_cmask,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/gt_clothes_mask/'+data['name'][0],gt_cmask)\n",
    "                \n",
    "                # Save target cloth\n",
    "                cloth =(data['color'][0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                cloth=(cloth*255).astype(np.uint8)\n",
    "                cloth=cv2.cvtColor(cloth,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/clothes/'+data['name'][0],cloth)\n",
    "                \n",
    "                # Save warped cloth\n",
    "                warpc =(warp_tcw[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                warpc=(warpc*255).astype(np.uint8)\n",
    "                warpc=cv2.cvtColor(warpc,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/warped_clothes/'+data['name'][0],warpc)\n",
    "                \n",
    "                # Save warped cloth refined via unet\n",
    "                warpcref =(warp_tcr[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "                warpcref=(warpcref*255).astype(np.uint8)\n",
    "                warpcref=cv2.cvtColor(warpcref,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite('../outputs/'+exp_name+'/warped_clothes_ref/'+data['name'][0],warpcref)\n",
    "            \n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "        step += 1\n",
    "        #print(step)\n",
    "        \n",
    "        \n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        \n",
    "        ##################################################\n",
    "        # Compute SSIM scores\n",
    "        def norm(tensor_list):\n",
    "            mins = tensor_list.min()\n",
    "            maxs = tensor_list.max()\n",
    "            normalized_data = (tensor_list - mins) / (maxs - mins)\n",
    "            return normalized_data\n",
    "        \n",
    "        # Normalize image to [0-1]\n",
    "        real_norm = norm(img)\n",
    "        fake_norm = norm(fake_image)\n",
    "\n",
    "        score = pytorch_ssim.ssim(real_norm, fake_norm)\n",
    "        score = score.item()\n",
    "        #print(\"SSIM for {}-----:\".format(step), score)\n",
    "        ssims.append(score)\n",
    "        ##################################################\n",
    "        \n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            # print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            # model.module.save('latest')\n",
    "            # np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "            pass\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "\n",
    "#         # Debug\n",
    "#         if i == 10:\n",
    "#             print(\"Exiting loop.\")\n",
    "#             #i = 0\n",
    "#             break\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    break\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        # np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecfbc5f-6d23-4ee7-99e1-0576146422e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute SSIM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663df66-6302-4142-9d0b-e5ec0fd69992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if category == \"all\":\n",
    "    print(\"No SSIM\") \n",
    "else:\n",
    "    score = np.array(ssims).mean()\n",
    "    print(\"SSIM score: {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110c101-71c8-474b-bac3-407a87466550",
   "metadata": {},
   "source": [
    "### Compute FID scores\n",
    "\n",
    "Scores on training image pairs. Different than VITON testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c2581-b2da-4ebe-b037-b5846a9771eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial_preprocessedv2_test is a copied version of partial_preprocessedv2_train.\n",
    "\n",
    "!python -m pytorch_fid '../outputs/eccv_vton/all_same' '../../datasets/decathlon_data/partial_preprocessedv2_test/test_img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52f252-162c-40dd-a6e8-3b33b8fc71aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ed3d588-fd66-4712-86c3-513d22d61b61",
   "metadata": {},
   "source": [
    "| Model  | Dataset | Test all SSIM (higher) | Test FID (lower) | Notes\n",
    "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
    "| FIFA (ECCV Sub) | VITON| 0.7975 | 88.288 | Trained on VITON dataset|\n",
    "| FIFA w/o Fabricator (NEW) | Decathlon Partial | **0.9010** | **58.813** | Trained on partial decathlon product item image pairs|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d1fe4-3b8d-406a-9d84-84142d800753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6793e5-d77e-4a09-be53-17cd73641b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a1974-0417-4789-80c1-2866c3c9b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script test-deca.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee5608-2d38-4745-9c09-3476be2e06b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
